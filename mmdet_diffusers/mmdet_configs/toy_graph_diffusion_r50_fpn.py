_base_ = [
    "mmdet::_base_/datasets/coco_detection.py",
    "mmdet::_base_/default_runtime.py",
]

import os
import sys
import inspect

# Make repo-root importable for `custom_imports` when launched via `mim train`,
# whose default sys.path does not include the config directory.
__cfg_file = inspect.currentframe().f_code.co_filename  # type: ignore[union-attr]
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__cfg_file), "..", "..")))

custom_imports = dict(imports=["mmdet_diffusers.mmdet3"], allow_failed_imports=False)

# Toy COCO dataset generated by: `python mmdet_diffusers/tools/make_toy_coco.py`
data_root = "datasets/toy_coco/"
metainfo = dict(classes=("person",), palette=[(220, 20, 60)])

num_classes = 1
num_nodes = 50
unk_id = num_classes

train_dataloader = dict(
    batch_size=1,
    num_workers=0,
    persistent_workers=False,
    collate_fn=dict(type="coco_graph_collate", num_nodes=num_nodes, unk_id=unk_id, shuffle_nodes=True),
    dataset=dict(
        data_root=data_root,
        metainfo=metainfo,
        ann_file="annotations/instances_train.json",
        data_prefix=dict(img="images/"),
        filter_cfg=dict(filter_empty_gt=False),
    ),
)
val_dataloader = dict(
    batch_size=1,
    num_workers=0,
    persistent_workers=False,
    collate_fn=dict(type="coco_graph_collate", num_nodes=num_nodes, unk_id=unk_id, shuffle_nodes=False),
    dataset=dict(
        data_root=data_root,
        metainfo=metainfo,
        ann_file="annotations/instances_val.json",
        data_prefix=dict(img="images/"),
        test_mode=True,
    ),
)
test_dataloader = val_dataloader

val_evaluator = dict(type="CocoMetric", ann_file=data_root + "annotations/instances_val.json", metric="bbox")
test_evaluator = val_evaluator

model = dict(
    type="GraphDiffusionDetector",
    data_preprocessor=dict(
        type="DetDataPreprocessor",
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_size_divisor=32,
    ),
    backbone=dict(
        type="ResNet",
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type="BN", requires_grad=True),
        norm_eval=True,
        style="pytorch",
        init_cfg=None,
    ),
    neck=dict(type="FPN", in_channels=[256, 512, 1024, 2048], out_channels=256, num_outs=5),
    num_classes=num_classes,
    num_proposals=num_nodes,
    diffusion_timesteps=1000,
    sampling_timesteps=1,
    box_scale=2.0,
    hidden_dim=256,
    dim_feedforward=2048,
    nhead=8,
    dropout=0.0,
    activation="relu",
    num_heads=2,
    deep_supervision=True,
    pooler_resolution=7,
    roi_featmap_strides=(4, 8, 16, 32),
    dim_dynamic=64,
    num_dynamic=2,
    num_cls_layers=1,
    num_reg_layers=1,
    use_geo_bias=True,
    geo_bias_type="mlp",
    geo_bias_scale=1.0,
    capture_graph_attn=False,
    use_label_state=True,
    label_state_scale=0.1,
    aniso_noise=False,
    score_thr=0.05,
    nms_iou_thr=0.6,
    max_per_img=100,
)

# Minimal 1-epoch schedule for smoke.
optim_wrapper = dict(optimizer=dict(type="AdamW", lr=1e-4, weight_decay=0.05))
param_scheduler = [
    dict(type="LinearLR", start_factor=0.001, by_epoch=False, begin=0, end=10),
    dict(type="MultiStepLR", by_epoch=True, begin=0, end=1, milestones=[1], gamma=0.1),
]

train_cfg = dict(type="EpochBasedTrainLoop", max_epochs=1, val_interval=1)
val_cfg = dict(type="ValLoop")
test_cfg = dict(type="TestLoop")

default_hooks = dict(logger=dict(interval=1), checkpoint=dict(interval=1))
